{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "Implement Page Rank Algorithm. (Use python or beautiful soup for implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOoJh-_jnY35",
    "outputId": "96811aab-b734-47a1-d06b-3ee3992a5060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install networkx beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpv6yVBwnY37",
    "outputId": "79139941-6e32-4cdf-f3e1-f5e4f8c7d69e"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class PageRank:\n",
    "    def __init__(self, damping_factor=0.85, max_iter=100, tol=1.0e-6):\n",
    "        self.damping_factor = damping_factor\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.graph = nx.DiGraph()\n",
    "\n",
    "    def add_edge(self, from_node, to_node):\n",
    "        self.graph.add_edge(from_node, to_node)\n",
    "\n",
    "    def compute_pagerank(self):\n",
    "        pagerank = nx.pagerank(self.graph, alpha=self.damping_factor, max_iter=self.max_iter, tol=self.tol)\n",
    "        return pagerank\n",
    "\n",
    "    def scrape_links(self, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            links = set()\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                links.add(link['href'])\n",
    "            return links\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {url}: {e}\")\n",
    "            return set()\n",
    "\n",
    "    def build_graph_from_urls(self, seed_url, depth=1):\n",
    "        urls_to_visit = [seed_url]\n",
    "        visited_urls = set()\n",
    "\n",
    "        for _ in range(depth):\n",
    "            new_urls = []\n",
    "            for url in urls_to_visit:\n",
    "                if url not in visited_urls:\n",
    "                    visited_urls.add(url)\n",
    "                    links = self.scrape_links(url)\n",
    "                    for link in links:\n",
    "                        self.add_edge(url, link)  # Create edges in the graph\n",
    "                        new_urls.append(link)\n",
    "            urls_to_visit = new_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V-33eg2nY39",
    "outputId": "fa818dd0-2fff-42d0-a878-c4bdcf0de30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping /wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License: No connection adapters were found for '/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License'\n",
      "Error scraping #United_States: Invalid URL '#United_States': No scheme supplied. Perhaps you meant https://#United_States?\n",
      "Error scraping /wiki/United_States_District_Court_for_the_Eastern_District_of_Pennsylvania: Invalid URL '/wiki/United_States_District_Court_for_the_Eastern_District_of_Pennsylvania': No scheme supplied. Perhaps you meant https:///wiki/United_States_District_Court_for_the_Eastern_District_of_Pennsylvania?\n",
      "Error scraping #cite_ref-12: Invalid URL '#cite_ref-12': No scheme supplied. Perhaps you meant https://#cite_ref-12?\n",
      "Error scraping /wiki/Category:CS1_French-language_sources_(fr): No connection adapters were found for '/wiki/Category:CS1_French-language_sources_(fr)'\n",
      "Error scraping #cite_note-30: Invalid URL '#cite_note-30': No scheme supplied. Perhaps you meant https://#cite_note-30?\n",
      "Error scraping /wiki/End-user_(computer_science): Invalid URL '/wiki/End-user_(computer_science)': No scheme supplied. Perhaps you meant https:///wiki/End-user_(computer_science)?\n",
      "Error scraping /w/index.php?title=Web_scraping&action=edit&section=17: Invalid URL '/w/index.php?title=Web_scraping&action=edit&section=17': No scheme supplied. Perhaps you meant https:///w/index.php?title=Web_scraping&action=edit&section=17?\n",
      "Error scraping /wiki/World_Wide_Web_Wanderer: Invalid URL '/wiki/World_Wide_Web_Wanderer': No scheme supplied. Perhaps you meant https:///wiki/World_Wide_Web_Wanderer?\n",
      "Error scraping /wiki/Internet_Archive: Invalid URL '/wiki/Internet_Archive': No scheme supplied. Perhaps you meant https:///wiki/Internet_Archive?\n",
      "Error scraping /wiki/Web_archiving: Invalid URL '/wiki/Web_archiving': No scheme supplied. Perhaps you meant https:///wiki/Web_archiving?\n",
      "Error scraping /wiki/Category:Articles_needing_additional_references_from_April_2023: No connection adapters were found for '/wiki/Category:Articles_needing_additional_references_from_April_2023'\n",
      "Error scraping #cite_note-impervawp2011-14: Invalid URL '#cite_note-impervawp2011-14': No scheme supplied. Perhaps you meant https://#cite_note-impervawp2011-14?\n",
      "Error scraping #Text_pattern_matching: Invalid URL '#Text_pattern_matching': No scheme supplied. Perhaps you meant https://#Text_pattern_matching?\n",
      "Error scraping #cite_note-18: Invalid URL '#cite_note-18': No scheme supplied. Perhaps you meant https://#cite_note-18?\n",
      "Error scraping /wiki/Special:BookSources/9781595936097: No connection adapters were found for '/wiki/Special:BookSources/9781595936097'\n",
      "Error scraping /wiki/Website: Invalid URL '/wiki/Website': No scheme supplied. Perhaps you meant https:///wiki/Website?\n",
      "Error scraping /wiki/Special:EditPage/Web_scraping: No connection adapters were found for '/wiki/Special:EditPage/Web_scraping'\n",
      "Error scraping /wiki/Portal:Current_events: No connection adapters were found for '/wiki/Portal:Current_events'\n",
      "Error scraping #: Invalid URL '#': No scheme supplied. Perhaps you meant https://#?\n",
      "Error scraping /wiki/Injunction: Invalid URL '/wiki/Injunction': No scheme supplied. Perhaps you meant https:///wiki/Injunction?\n",
      "Error scraping #cite_note-1: Invalid URL '#cite_note-1': No scheme supplied. Perhaps you meant https://#cite_note-1?\n",
      "Error scraping /wiki/ISBN_(identifier): Invalid URL '/wiki/ISBN_(identifier)': No scheme supplied. Perhaps you meant https:///wiki/ISBN_(identifier)?\n",
      "Error scraping #cite_note-29: Invalid URL '#cite_note-29': No scheme supplied. Perhaps you meant https://#cite_note-29?\n",
      "Error scraping #cite_ref-28: Invalid URL '#cite_ref-28': No scheme supplied. Perhaps you meant https://#cite_ref-28?\n",
      "Error scraping /wiki/History_of_the_World_Wide_Web: Invalid URL '/wiki/History_of_the_World_Wide_Web': No scheme supplied. Perhaps you meant https:///wiki/History_of_the_World_Wide_Web?\n",
      "Error scraping #cite_ref-2: Invalid URL '#cite_ref-2': No scheme supplied. Perhaps you meant https://#cite_ref-2?\n",
      "Error scraping /wiki/Special:MyTalk: No connection adapters were found for '/wiki/Special:MyTalk'\n",
      "Error scraping #cite_note-12: Invalid URL '#cite_note-12': No scheme supplied. Perhaps you meant https://#cite_note-12?\n",
      "Error scraping /wiki/JSON: Invalid URL '/wiki/JSON': No scheme supplied. Perhaps you meant https:///wiki/JSON?\n",
      "Error scraping /wiki/Category:All_articles_needing_additional_references: No connection adapters were found for '/wiki/Category:All_articles_needing_additional_references'\n",
      "Error scraping /wiki/ISSN_(identifier): Invalid URL '/wiki/ISSN_(identifier)': No scheme supplied. Perhaps you meant https:///wiki/ISSN_(identifier)?\n",
      "Error scraping /wiki/Data_wrangling: Invalid URL '/wiki/Data_wrangling': No scheme supplied. Perhaps you meant https:///wiki/Data_wrangling?\n"
     ]
    }
   ],
   "source": [
    "pagerank = PageRank()\n",
    "\n",
    "# Example: Build graph from URLs (seeds)\n",
    "# https://en.wikipedia.org/wiki/Web_scraping\n",
    "# https://medium.com/@arti.singh280/list/the-quantum-world-6126d55e1882\n",
    "seed_url = \"https://docs.quantum.ibm.com/api/qiskit/release-notes/0.44#misc-deprecations\"  # Change this URL as needed\n",
    "pagerank.build_graph_from_urls(seed_url, depth=2)\n",
    "\n",
    "# Compute PageRank\n",
    "ranks = pagerank.compute_pagerank()\n",
    "\n",
    "# Print the PageRank scores\n",
    "print(\"PageRank Scores:\")\n",
    "for url, score in ranks.items():\n",
    "    print(f\"{url}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89EIJis_otPP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
